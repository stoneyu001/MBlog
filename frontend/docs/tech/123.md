---
title: 123
---

# 123

### 功能的实现？
#为什么用go
轻量化，小型项目效率高，资源占用少，并发处理能力强，代码简洁易懂，部署方便，编译后是二进制文件不需额外依赖
#搜索？
- 用的是一个轻量级的minisearch的引擎库
- 构建站点时创建所有文档内容（包括标题，正文）的索引以json格式存储起来，
- 做了一个简单的分词处理，再根据权重排序（先看标题再看）就实现了本地搜索
#postgre
PostgreSQL 原生支持 JSON 类型和相关操作，便于存储博客的元数据和标签等非结构化数据
#request类型是什么
前端请求到后端要经过一个中间件处理，每次经过就会记录一次request事件
#评论
- 当用户提交评论时，前端通过 POST 请求发送到 /api/comments 接口
- 评论数据使用 JSON 格式传输，包含文章路径、评论内容、父评论ID等信息
- CommentService负责处理评论请求转成数据库格式传入
- 前端通过 GET 请求获取特定文章的评论列表，后端从数据库查询评论数据，组织成树状结构
#标签
- 1. 自动标签：
- 使用 TF-IDF 算法自动从文章内容提取关键词作为标签
- 提取过程：
1. 预处理文章内容：去除代码块、链接等非文本内容
2. 使用简单分词：将文本分割成单词或词组
3. 过滤停用词：移除"的"、"了"等无意义词语
4. 计算词语权重：使用 TF-IDF 算法计算每个词的重要性
5. 选择权重最高的词：默认选择前5个作为标签
6. 文章展示时：
- VitePress 自动解析 frontmatter
- 将标签渲染到页面指定位置
- 为标签添加点击事件和样式
#埋点数据
- 前端使用tracking大类下的多种方法，监听各种事件来采集数据
- 采集的数据会进行批量处理（有一个local缓冲池）多条数据合并成一个请求和Web Worker异步上传
- 主要通过中间件 TrackingMiddleware 自动采集用户访问数据
- 通过 HTTP 请求自动发送到后端 /api/tracking 接口，tracking 包负责接收和处理埋点数据数据会被存储到 PostgreSQL 数据库中
#可视化
- 用的是基于JavaScript的echarts可视化库，很适合动态更新与交互
- 前端页面发起对应请求后，会调用后端api接口执行对应统计函数
- 统计函数先提取数据，再进行聚合处理为可视化需要的格式然后返回到前端
- 前端拿到数据通过echarts库画出对应的图
#CRUD
- 通过 volumes 挂载实现持久化,不仅保证容器内文件不会丢失
- 同时做到了宿主机和前后端容器内文章的共享，是三向同步的关系
- 后端容器的共享主要用于- 文件的增删改查操作，构建站点目录，更新侧边栏配置
#总体联系逻辑
- 宿主机80端口映射前端容器80端口，当用户访问时，从容器内对应位置读取文件返回。
- 其他的评论，统计等请求才会通过后端容器3000端口进行处理并返回数据
- 容器间通过内部网络通信
#容器内通信
- 容器运行在同一个Docker网络中
- 可以通过容器名称互相访问，就像是在一个局域网内，容器可以通过名字直接找到对方并通信
- 类似内部DNS解析
#Nginx的作用
Nginx 作为整个系统的入口，接收所有外部请求，对于静态文件请求（如文章、图片）直接返回文件内容，对于动态请求（如评论、统计）则转发给后端处理，提高了静态资源的访问效率，又保护了后端服务的安全性。
#项目构建
作为答辩学生，我来说明项目的镜像构建过程：
1. 前端镜像构建：
```
基础镜像 nginx:alpine
↓
复制构建好的静态文件到 /usr/share/nginx/html
↓
配置 nginx 反向代理
↓
暴露80端口
```
2. 后端镜像构建：
```
基础镜像 golang:1.21-alpine（构建阶段）
↓
复制并下载依赖
↓
构建Go程序
↓
基础镜像 alpine（运行阶段）
↓
复制编译好的程序
↓
暴露3000端口
```
3. 数据库：
- 直接使用 postgres:15-alpine 镜像
通过 docker-compose 可以一键完成整个构建和启动过程，各个容器通过 Docker 网络通信，文章内容通过 Volume 共享。

### 演示思路
先介绍主页，
进入内容页，侧边栏，大纲，内容。介绍阅读体验，介绍搜索，标签，评论，埋点采集。


umami
Clarity